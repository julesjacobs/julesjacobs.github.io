---
title:  "Combining probabilities? Try a logarithm."
---
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Correlated probabilities? Try a logarithm.</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<p>Suppose that we have a patient and are trying to determine whether his leg is broken. A general practitioner investigates the patient and a radiologist looks at a scan of his leg. Both doctors give their conclusion in the form of a probability that the leg is broken, <span class="math inline">\(P_{GP}\)</span> and <span class="math inline">\(P_{R}\)</span>. How do we combine these probabilities into one? If these were independent then we could just multiply <span class="math inline">\(P_{GP}\cdot P_{R}\)</span>, but it’s likely that both the GP and the radiologist will have the same opinion, so they are not independent. Furthermore, maybe the opinion of the radiologist is more accurate than the opinion of the general practitioner, because the radiologist looks at a scan of the leg.</p>
<p>We could forget that these are probabilities altogether, and focus on the decision of whether to operate the patient or not. We assign a combined score <span class="math inline">\(f(P_{GP},P_{R})\)</span> in some way, and then look empirically for a decision boundary <span class="math inline">\(f(P_{GP},P_{R})&lt;\alpha\)</span> that gives us a trade-off between the false positive and false negative rate. The question remains which <span class="math inline">\(f\)</span> we should use.</p>
<p>A linear model is usually the first you’d try, <span class="math inline">\(f(P_{GP},P_{R})=aP_{GP}+bP_{R}\)</span>, but I claim that <span class="math inline">\(f(P_{GP},P_{R})=P_{GP}^{a}\cdot P_{R}^{b}\)</span> is more natural. If the probabilities were independent then <span class="math inline">\(a=1,b=1\)</span> would give <span class="math inline">\(P_{GP}\cdot P_{R}\)</span>. Choosing different <span class="math inline">\(a,b\)</span> weighs the opinions, e.g. <span class="math inline">\(a=1/3\)</span>, <span class="math inline">\(b=2/3\)</span>.</p>
<p>This is equivalent to training a linear model on the log probabilities <span class="math inline">\(\log P_{GP}\)</span> and <span class="math inline">\(\log P_{R}\)</span>, because <span class="math inline">\(\log(P_{GP}^{a}\cdot P_{R}^{b})=a\log P_{GP}+b\log P_{R}\)</span>. The log probability is natural from the point of view of information theory: log probability is measured in bits. Probabilities get multiplied, bits get added.</p>
<p>If you’re training a classifier on probabilities, try a logarithm.</p>
</body>
</html>
