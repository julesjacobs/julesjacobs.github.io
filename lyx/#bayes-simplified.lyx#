#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Bayes' rule simply
\end_layout

\begin_layout Standard
Bayes' rule is usually written 
\begin_inset Formula 
\begin{align*}
P(\theta|x) & =P(x|\theta)\frac{P(\theta)}{P(x)}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In practice we're trying to learn about some model parameter 
\begin_inset Formula $\theta$
\end_inset

 given some observation 
\begin_inset Formula $x$
\end_inset

.
 The model 
\begin_inset Formula $P(x|\theta)$
\end_inset

 tells us how observations are influenced by the model parameter.
 This seems simple enough, but a small change in notation reveals how simple
 Bayes' rule is.
 Let us call 
\begin_inset Formula $P(\theta)$
\end_inset

 the prior on 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $P'(\theta)$
\end_inset

 the posterior on theta.
 Then Bayes' rule says:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P'(\theta) & \propto P(x|\theta)P(\theta)
\end{align*}

\end_inset

We got rid of the denominator 
\begin_inset Formula $P(x)$
\end_inset

 because it's just a normalisation to make the total probability sum to
 1, and instead say that 
\begin_inset Formula $P'(\theta)$
\end_inset

 is proportional to 
\begin_inset Formula $P(x|\theta)P(\theta)$
\end_inset

.
 The value 
\begin_inset Formula $P(x|\theta)P(\theta)=P(x,\theta)$
\end_inset

 is the joint probability of seeing a given pair 
\begin_inset Formula $(x,\theta)$
\end_inset

, so we can also write Bayes' rule as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P'(\theta)\propto & P(x,\theta)
\end{align*}

\end_inset

So up to normalisation, the posterior is just substituting the actual observatio
n 
\begin_inset Formula $X=x$
\end_inset

 into the joint distribution.
 How can we interpret this? Imagine that we have a robot whose current state
 of belief is given by 
\begin_inset Formula $P(x,\theta)$
\end_inset

 and that 
\begin_inset Formula $x,\theta$
\end_inset

 only have a finite number of possible values, so that the robot has stored
 a probability 
\begin_inset Formula $P(x,\theta)$
\end_inset

 for each pair 
\begin_inset Formula $(x,\theta)$
\end_inset

.
 Suppose that the robot now learns 
\begin_inset Formula $X=x$
\end_inset

 by observation.
 What does it do to compute its posterior belief? It first sets all 
\begin_inset Formula $P(y,\theta)=0$
\end_inset

 for 
\begin_inset Formula $y\neq x$
\end_inset

 because the actual observed value is 
\begin_inset Formula $x$
\end_inset

.
 Then it renormalises the probabilities to make 
\begin_inset Formula $P(x,\theta)$
\end_inset

 sum to 1 again.
 That's all Bayes' rule is: simply delete the possibilities that are incompatibl
e with the observation, and renormalise the remainder.
\end_layout

\end_body
\end_document
