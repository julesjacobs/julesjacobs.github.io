\input{ppreamble}
\newcommand{\id}[1]{\lstinline\|#1\|}

\title{Bottom-up rewriting with smart constructors, hereditary substitution \& \\normalization by evaluation}
\author{\large{Jules Jacobs}}
\date{\normalsize	\today}

\begin{document}
\maketitle
% \blfootnote{Contact information: \url{https://julesjacobs.com}}

\begin{abstract}
  \noindent
  This is an introduction to these three well-known techniques for rewriting to normal form, and how
  to use them to optimize regular expressions and compute $\beta$ and $\eta$ normal forms of lambda terms.
  We will see that these techniques share the same key idea, but differ in how binders are represented and how substitution is handled:
  \begin{align*}
    \text{Hereditary substitution} &= \text{smart constructors} + \text{AST substitution} \\
    \text{Normalization by evaluation} &= \text{smart constructors} + \text{HOAS substitution}
  \end{align*}
  The key idea is that the smart constructors always create normal forms by first
  performing applicable rewrite rules to the new term that we want to construct.
  By constructing the rewritten term using smart constructors, we get a mutually recursive set of functions that rewrite to normal form.
  If we have rewrite rules that do substitution, then the substitution function must also construct its new term using the smart constructors, which makes it part of the mutual recursion.

  The formulation of normalization by evaluation in this note is slightly simpler than some conventional presentations,
  which (in my view) intertwine conversion to and from HOAS with normalization itself.%
  \footnote{
    E.g., the one on wikipedia \url{https://en.wikipedia.org/wiki/normalization_by_evaluation}.
    Note how \id{reify} does both HOAS $\to$ AST conversion and $\eta$-long normal form creation,
    and \id{meaning} does both AST $\to$ HOAS conversion and evaluation.
    Some approaches, such as \emph{finally tagless} \cite{FinallyTagless2007} do use HOAS throughout.
  }
\end{abstract}

\tableofcontents

\newpage
\section{Introduction}

\newcommand{\emp}{0}
\newcommand{\eps}{1}
\newcommand{\seq}{\cdot}
\newcommand{\md}{\ \mid \ }

Suppose we want to simplify regular expressions consisting of the following operations.
The symbol $0$ represents the regex that doesn't match anything, $1$ represents the regex that only matches the empty string,
$`c`$ represents a single character, $(+)$ represents union, $(\cdot)$ represents concatenation, and $*$ represents repetition:
\begin{align*}
  r \in \mathsf{Re} \ ::=\  \emp \md \eps \md `c` \md r + r \md r \seq r \md r^*,
\end{align*}
We want to rewrite by repeatedly using the following equations from left to right: \vspace{-0.7cm}

\begin{minipage}[t]{0.3\textwidth}
  \begin{align*}
    r + \emp &= r \\
    \emp + r &= r \\
    r + r &= r \\
    (r + s) + t &= r + (s + t) \\
  \end{align*}
\end{minipage}
\begin{minipage}[t]{0.3\textwidth}
  \begin{align*}
    r \seq \emp &= \emp \\
    \emp \seq r &= \emp \\
    r \seq \eps &= r \\
    \eps \seq r &= r \\
    (r \seq s) \seq t &= r \seq (s \seq t) \\
  \end{align*}
\end{minipage}
\begin{minipage}[t]{0.3\textwidth}
  \begin{align*}
    \emp^* &= \eps \\
    \eps^* &= \eps \\
    (r^*)^* &= r^*
  \end{align*}
\end{minipage}

For example, $(a \seq 0^*)^{**} + 0 = a^*$.

Simplifying regexes using those equations is useful for implementing regular expression matching with Brzozowski derivatives \cite{brzozowski64,owens_reppy_turon_2009}.
The point isn't this particular example; rewriting expressions to normal form for a given set of equations is more broadly useful.

The naive way to do this is to take the regular expression $r$, and try to find some subnode of $r$ where one of the left hand sides of the equations can be rewritten to the right hand side.
If we repeat this as much as possible, until no equation matches any subnode, we have rewritten the regex to normal form.
The problem with this approach is that it is inefficient and not even very easy to implement. At each step we have to search through $r$ to find a place to apply a rewrite rule.

A more systematic way to do this is to schedule the rewrites bottom up. For instance, if $r = r_1 + r_2$ then we first recursively rewrite $r_1$ and $r_2$ to normal form. We then only need to check if $r_1 + r_2$ itself is in normal form. If it is, then we're done. If one of the left hand sides of the equations match, then we apply the rewrite rule. We then start the whole normalization process all over again, because after we've applied the rewrite rule there might be new opportunities for further rewriting.

This is better, but still not great. Suppose $r = (r_1 + r_2) + r_3$, and we've already rewritten $r_1,r_2,r_3$ to normal form. Now the associativity rewrite rule wants to rewrite this to $r_1 + (r_2 + r_3)$. This is a new regular expression, so maybe more rewrite rules match. However, we do know that $r_1, r_2, r_3$ themselves are still in normal form. So in order to rewrite $r_1 + (r_2 + r_3)$ to normal form, we don't need to recursively re-normalize $r_1, r_2, r_3$. We only need to check if any rewrite rule matches for the two newly created $(+)$ nodes. We thus want to keep track of which nodes are already in normal form, so that we never need to recurse into them again to uselessly try and fail to rewrite them further. Note we do need to \emph{look into} nodes that are already in normal form: if $r_2 = r_{21} + r_{22}$ then further rewrites do apply to $r_2 + r_3$, even if $r_2$ and $r_3$ are in normal form. This may seem like it can get a little bit complicated, but in the next section we will discuss a well known technique to do this easily and very efficiently.



\section{Bottom-up rewriting with smart constructors}

Let us first define a data type of regular expressions:

\begin{lstlisting}
enum Re:
  case Emp // 0
  case Eps // 1
  case Chr(c:Char) // 'c'
  case Seq(a:Re, b:Re) // r cdot s
  case Alt(a:Re, b:Re) // r + s
  case Star(a:Re) // r*
\end{lstlisting}

\subsection{Smart constructors}

The key idea is to define \emph{smart constructors} \id{seq}, \id{alt}, and \id{star} for the ordinary constructors \id{Seq}, \id{Alt}, and \id{Star}. We want these smart constructors to satisfy the following property:

\emph{If we use a smart constructor on values that are in normal form, it must return a value in normal form.}

Here's the one for \lstinline|seq|:

\begin{lstlisting}
def seq(a:Re, b:Re):Re =
  (a,b) match {
    case (Re.Emp,_) => Re.Emp
    case (_,Re.Emp) => Re.Emp
    case (Re.Eps,x) => x
    case (x,Re.Eps) => x
    case (Re.Seq(x,y),b) => seq(x,seq(y,b))
    case _ => Re.Seq(a,b)
  }
\end{lstlisting}

We check if any of the equations for $(\cdot)$ match, and if so we return the right hand side. Whenever we construct a new node after a rewrite, we \emph{have to use the smart constructors}. That guarantees that the returned value is in normal form. If no equation matches (last case), we can use the ordinary constructor \lstinline|Seq|.

Here are the smart constructors \lstinline|alt| and \lstinline|star|:

\begin{lstlisting}
def alt(a:Re, b:Re):Re =
  (a,b) match {
    case (Re.Emp,x) => x
    case (x,Re.Emp) => x
    case (Re.Alt(x,y),b) => alt(x,alt(y,b))
    case _ => if(a==b) a else Re.Alt(a,b)
  }

def star(a:Re):Re =
  a match {
    case Re.Emp => Re.Eps
    case Re.Eps => Re.Eps
    case Re.Star(_) => a
    case _ => Re.Star(a)
  }
\end{lstlisting}

\subsection{Converting to normal form}

To convert a regular expression to normal form, we simply \emph{"copy"} it with the smart constructors.
Let's call this idea \emph{smart copying}: like a copy function, but calling the smart constructors instead.

\begin{lstlisting}
def norm(a:Re):Re =
  a match {
    case Re.Emp => Re.Emp
    case Re.Eps => Re.Eps
    case Re.Chr(c) => Re.Chr(c)
    case Re.Alt(a,b) => alt(nf(a),nf(b))
    case Re.Seq(a,b) => seq(nf(a),nf(b))
    case Re.Star(a) => star(nf(a))
  }

val r = Re.Alt(Re.Star(Re.Star(Re.Seq(Re.Chr('a'),Re.Star(Re.Emp)))),Re.Emp)
norm(r) // Star(Chr('a'))
\end{lstlisting}

By the property that smart constructors return normal forms if you pass them normal forms, this function will return a normal form. What's more, this is very efficient: we only recurse over the initial regular expression \emph{once}, and we \emph{only ever allocate regular expressions that are in normal form}. We never allocate an intermediate value like $(r_1 + r_2) + r_3$ to which a rewrite rule applies; we rewrite it before even constructing it.

\subsection{Handling commutativity}

Suppose we also want to use commutativity $r + s = s + r$. This is nice, because then if we have $(r + s) + r$ we can use commutativity and associativity to rewrite that to $s + (r + r)$, so that the cancellation rule $r + r = r$ can be used to simplify it. We can't keep repeatedly rewriting using commutativity, because that would result in an infinite loop. What we want is to bring equal regexes next to each other, so that the cancellation rule applies.

To do this, we define an \emph{ordering} $(<)$ on regular expressions, and rewrite $r + s = s + r$ only if $s < r$. This will bring longer sequences $r_1 + r_2 + \cdots + r_n$ into sorted order, so that adjacent equal elements can be canceled. Any ordering will do. A convenient option is to sort them by their hash code. That leads to the following smart constructor:

\begin{lstlisting}
def alt1(a:Re, b:Re):Re =
  (a,b) match {
    case (Re.Emp,x) => x
    case (x,Re.Emp) => x
    case (Re.Alt(x,y),b) => alt1(x,alt1(y,b))
    case (a,Re.Alt(x,y)) =>
      if(a==x) b
      else if(a.hashCode() < x.hashCode()) Re.Alt(a,b)
      else alt1(x,alt1(a,y))
    case _ =>
      if(a==b) a
      else if(a.hashCode() < b.hashCode()) Re.Alt(a,b)
      else Re.Alt(b,a)
  }
\end{lstlisting}

This smart constructor is able to do that optimization:

\begin{minipage}{\textwidth}\begin{lstlisting}
val a = Re.Chr('a')
val b = Re.Chr('b')
alt(a,alt(b,a)) // Alt(Chr('a'), Alt(Chr('b'), Chr('a')))
alt1(a,alt1(b,a)) // Alt(Chr('b'), Chr('a'))
\end{lstlisting}\end{minipage}

\subsection{Optimizing at parse time}

As you can see in the previous example, an alternative to first constructing a regex and then converting it to normal form, is to use the smart constructors to construct the initial regex in the first place. The parser could call the smart constructors instead of the ordinary constructors.

This is what the JVM does when converting JVM bytecode to its sea-of-nodes intermediate representation \cite{click95}. It speeds up the JIT compiler because simple local rewrite rules are able to shrink the IR significantly, so the rest of the compiler has to wade though less code. In fact, the local rewrite rules are so effective in combination with the sea of nodes IR that you could potentially write a reasonably good compiler by just doing optimization with smart constructors.


\section{Better normal form representations}

The implementation of the smart constructor that handles commutativity is rather complicated. We're essentially implementing a very bad version of bubble sort. We even need separate cases for an element in the middle of the list and an element at the end of the list.

A better way is to use a representation of regular expressions tailored to normal forms. We represent n-ary sequential composition as a list. This builds associativity $(r \seq s) \seq t = r \seq (s \seq t)$ into the representation. We represent n-ary alternative with a set. This builds associativity $(r + s) + t = r + (s + t)$ and commutativity $r + s = s + r$ and idempotence $r + r = r$ into the representation.

\begin{lstlisting}
enum Re2:
  case Chr(a:Char)
  case Seq(rs:List[Re2])
  case Alt(rs:Set[Re2])
  case Star(r:Re2)
\end{lstlisting}

We no longer need the \lstinline|Eps| and \lstinline|Emp| classes for $0$ and $1$, because we can represent them as empty alternative and sequence nodes.

\begin{lstlisting}
val emp2 = Re2.Alt(Set())
val eps2 = Re2.Seq(List())
\end{lstlisting}

The smart constructors for \id{Seq} and \id{Alt} are significantly simpler with the \id{Re2} representation:

\begin{lstlisting}
def seq2(rs:List[Re2]):Re2 = {
  val rs2 = rs.flatMap{case Re2.Seq(rs) => rs; case x => List(x)}
  if(rs2.contains(emp2)) emp2
  else if(rs2.size == 1) rs2.head
  else Re2.Seq(rs2)
}



def alt2(rs:Set[Re2]):Re2 = {
  val rs2 = rs.flatMap{case Re2.Alt(rs) => rs; case x => Set(x)}
  if(rs2.size == 1) rs2.head
  else Re2.Alt(rs2)
}
\end{lstlisting}

The smart constructor for \id{Star} does not change much:

\begin{lstlisting}
def star2(a:Re2):Re2 =
  a match {
    case Re2.Alt(rs) if rs.isEmpty => eps2
    case Re2.Seq(rs) if rs.isEmpty => eps2
    case Re2.Star(_) => a
    case _ => Re2.Star(a)
  }
\end{lstlisting}

We can define conversion functions from \id{Re} to \id{Re2} and vice versa that put the regex in normal form.
Alternatively, we could also use the \id{Re2} representation throughout and remove \id{Re} entirely, but I show the conversion functions here for illustration.
We use the name \id{norm} : \id{Re} $\to$ \id{Re2} because normalization is now done by conversion to the tailored normal form representation:

\begin{lstlisting}
def norm(r:Re):Re2 =
  r match {
    case Re.Eps => eps2
    case Re.Emp => emp2
    case Re.Chr(c) => Re2.Chr(c)
    case Re.Alt(a,b) => alt2(Set(norm(a),norm(b)))
    case Re.Seq(a,b) => seq2(List(norm(a),norm(b)))
    case Re.Star(a) => star2(norm(a))
  }
\end{lstlisting}

We use the name \id{reify} : \id{Re2} $\to$ \id{Re} because this conversion reifies the normal form representation back to the original syntax:

\begin{lstlisting}
def reify(r:Re2):Re =
  r match {
    case Re2.Chr(c) => Re.Chr(c)
    case Re2.Seq(rs) => fold1(rs.map(reify), Re.Eps, Re.Seq)
    case Re2.Alt(rs) => fold1(rs.map(reify), Re.Eps, Re.Alt)
    case Re2.Star(r) => Re.Star(reify(r))
  }
\end{lstlisting}

Some examples:
\begin{lstlisting}
val c = Re2.Chr('c')
val d = Re2.Chr('d')
val z = alt2(Set(c,d,emp2,eps2))
alt2(Set(z,z,c)) // Alt(Set(Chr(c), Chr(d), Seq(List())))
seq2(List(emp2, c, d)) // Alt(Set())
reify(z) // Alt(Eps,Alt(Chr(d),Chr(c)))
\end{lstlisting}


\section{Hereditary substitution}

\newcommand{\ap}{\mathsf{app}}
\newcommand{\steps}{\leadsto}

While regexes are fun, simplification becomes more interesting when binders are involved, such as with lambda calculus with $\lambda x. e$ and function application $f\ x \equiv \ap(f,x)$:
\begin{align*}
  e \in \mathsf{Tm} \ ::=\  x \md \lambda x. e \md \ap(e,e)
\end{align*}
We want to simplify with respect to the $\beta$-rule that applies a lambda to an argument:
\begin{align*}
  \ap((\lambda x. e_1), e_2) \steps e_1[x := e_2]
\end{align*}
We could start with a lambda term and keep applying this rule wherever it applies (and choosing arbitrarily when it applies in multiple places), we'd like to do something like the smart constructors we used for regexes.\footnote{Applying the $\beta$-rule repeatedly may not terminate for all lambda terms, such as for the term $\ap((\lambda x. \ap(x,x)), \lambda x. \ap(x,x))$. We will assume that the lambda term that we want to simplify satisfies strong normalization, which means that any order of applying the $\beta$-rule will eventually terminate. This is guaranteed if the term type-checks in the simply typed lambda calculus, for instance.}
One method for doing that is called \emph{hereditary substitution} \cite{keller:inria-00520606}.

Hereditary substitution can be viewed as a smart constructor for $\ap$: whenever $\ap(e_1,e_2)$ sees that $e_1 = \lambda x, e$ is a lambda term, it will do the substitution instead of constructing an $\ap$ syntax tree node.

To turn this idea into code, we will first need to decide how to represent lambda terms in our program.
We could represent variables $x$ as strings \id{"x"}, but this makes it quite difficult to write a correct substitution function in a purely functional way.
The difficulty is that we want to apply the $\ap$ rule under lambdas, so the terms we are substituting may have free variables that need to be renamed to avoid name clashes.
At first, you may think that giving all variables in the initial lambda term unique names solves the name clash problem, but that isn't the case: because of substitution the terms get copied so the invariant that all names are unique gets violated, and name clashes can still result.

Instead of string names, we're going to use De Bruijn indices \cite{BruijnIndex2021}.
We represent a variable with a number that indicates how many $\lambda$ nesting levels we need to traverse to find the $\lambda$ that the variable belongs to.
If we have a term $\lambda x. \lambda y. \lambda z. x$ then the De Bruijn index of $x$ will be $2$, because we need to traverse over the $\lambda z$ and $\lambda y$ in order to find the $\lambda x$.
This way, we do not have to use any variable names, and can simply write $\lambda x. \lambda y. \lambda z. x \equiv \lambda. \lambda. \lambda. 2$.
The $\ap$ nodes have no effect on the De Bruijn indices.
For instance, the term $\lambda. \lambda. \ap(0,\lambda. \ap(0,2))$ means $\lambda x. \lambda y. \ap(y, \lambda z. \ap(z,x))$.
The details of this encoding are not so important and I leave them to the next subsection: the important part is that this allows us to write a substitution function without much trouble.



We first define De Bruijn syntax tree nodes:
\begin{lstlisting}
enum Db:
  case Var(x:Int)
  case Lam(a:Db)
  case App(a:Db, b:Db)
\end{lstlisting}

We define a substitution function \id{subst(e,f)} that substitutes the term \id{f(i)} for each variable \id{i} in \id{e}. This is called a \emph{parallel substitution} because it substitutes terms for all variables simultaneously:

\begin{minipage}{\textwidth}\begin{lstlisting}
def subst(a:Db, f:Int => Db):Db =
  a match {
    case Db.Var(n) => f(n)
    case Db.Lam(a) => Db.Lam(subst(a,liftS(f))) // we will get to the liftS function later
    case Db.App(a,b) => Db.App(subst(a,f),subst(b,f))
  }
\end{lstlisting}\end{minipage}

Notice that the \id{subst} function is calling the smart constructor \id{app}, which we still need to define!

In terms of the parallel substitution function \id{subst(e,f)} we can define \id{subst0(e,v)} that substitutes only the first variable $0 \mapsto$ \id{v} in \id{e}.
Now that variable $0$ is gone, we have to decrement all other variable indices:

\begin{lstlisting}
def subst0(e:Db, v:Db):Db = subst(e, (n) => if(n==0) v else Db.Var(n-1))
\end{lstlisting}

With this substitution function at hand, we can finally define the smart constructor \id{app}:

\begin{lstlisting}
def app(a:Db, b:Db):Db =
  a match {
    case Db.Lam(e) => subst1(e, b)
    case _ => Db.App(a,b)
  }
\end{lstlisting}

The mutual recursion between \id{subst} and \id{app} ensures that no $\ap(e_1,e_2)$ term gets created where $e_1$ is a lambda.

We can "smart copy" a lambda term to $\beta$-normalize it:

\begin{lstlisting}
def norm(a:Db):Db =
  a match {
    case Db.Var(n) => Db.Var(n)
    case Db.Lam(a) => Db.Lam(norm(a))
    case Db.App(a,b) => app(norm(a),norm(b))
  }
\end{lstlisting}

That's all there's to it!

\subsection{De Bruijn indices}

The \id{liftS} function lifts a substitution over a lambda.
To implement this, we first define a renaming function \id{rename(e,f)} that renames all variables \id{i} to \id{f(i)} in \id{e}:

\begin{lstlisting}
def liftR(f : Int => Int): Int => Int =
  (n) => if(n==0) 0 else f(n-1) + 1

def rename(a:Db, f:Int => Int):Db =
  a match {
    case Db.Var(n) => Db.Var(f(n))
    case Db.Lam(a) => Db.Lam(rename(a,liftR(f)))
    case Db.App(a,b) => Db.App(rename(a,f),rename(b,f))
  }
\end{lstlisting}

Using these, we can implement \id{shift} and \id{liftS}:

\begin{lstlisting}
def shift(e:Db, f:Int => Db):Int => Db =
  (n) => if(n==0) e else f(n-1)

def liftS(f : Int => Db):Int => Db =
  shift(Db.Var(0), k => rename(f(k), (_+1)))
\end{lstlisting}

The function \id{Var} is the identity substitution, so \id{shift(e,Var)} substitutes $0 \mapsto e$ and decrements all other variables by $1$, so we can now define \id{subst0} more concisely as:

\begin{lstlisting}
def subst0(e:Db, v:Db):Db = subst(e, shift(v,Db.Var))
\end{lstlisting}

\section{Untyped normalization by evaluation}

A more funky representation for lambda terms is \emph{higher order abstract syntax} (HOAS) \cite{pfenning88}.
We represent lambda nodes \emph{as its substitution function}: the lambda term $\lambda x. e$ gets represented as a Scala function that does $f(v) = e[x \mapsto v]$.
The return value is another lambda term, that is again represented in this HOAS representation.
We call the data type for lambda terms in this representation \id{Hs}:

\begin{lstlisting}
enum Hs:
  case Lam(f:Hs => Hs)
  case App(a:Hs, b:Hs)
\end{lstlisting}

Here's an example term $\lambda x. \lambda y. \ap(y, \lambda z. \ap(x,z))$:

\begin{lstlisting}
Hs.Lam(x => Hs.Lam(y => Hs.App(y, Hs.Lam(z => Hs.App(x,z)))))
\end{lstlisting}

The smart constructor \id{app} is now easy to write:

\begin{lstlisting}
def app(a:Hs, b:Hs):Hs =
  a match {
    case Hs.Lam(f) => f(b)
    case _ => Hs.App(a,b)
  }
\end{lstlisting}

The issue is that this doesn't mutually recursively call itself, like the hereditary substitution did.
We can fix that by using \id{app} instead of \id{App} in the original lambda terms we construct:

\begin{lstlisting}
Hs.Lam(x => Hs.Lam(y => app(y, Hs.Lam(z => app(x,z)))))
\end{lstlisting}

If we do this consistently, then the only place in our program where the constructor \id{App} is called is in \id{app}, and there we have made sure that the the first argument isn't a lambda, so we're guaranteed to get a $\beta$ normal form.

Instead of writing our lambda terms using \id{app} in the first place, we can write a smart copy function that does it for us:

\begin{lstlisting}
def norm(a:Hs):Hs =
  a match {
    case Hs.Lam(f) => Hs.Lam(x => norm(f(x)))
    case Hs.App(a,b) => app(norm(a),norm(b))
  }
\end{lstlisting}

This is called \emph{normalization by evaluation} \cite{berger91}.\footnote{Conventionally, normalization by evaluation is intertwined with conversion to and from HOAS. I find that confusing, because it intertwines separate concerns. So I opted to redefine "normalization by evaluation" to mean what the \id{norm} function does, namely HOAS $\to$ HOAS normalization, and handle conversion to and from HOAS separately.}

\subsection{From ordinary lambda terms to HOAS and back}

This may all seem incredibly weird, so we're going to write functions that convert from ordinary lambda terms (where variables are represented as strings) to \id{Hs} terms and back:

\begin{lstlisting}
enum Tm:
  case Var(x:String)
  case Lam(x:String, a:Tm)
  case App(a:Tm, b:Tm)
\end{lstlisting}

Conversion from \id{Tm} to \id{Hs}:

\begin{lstlisting}
def eval(env:Map[String,Hs], a:Tm):Hs =
  a match {
    case Tm.Var(x) => env(x)
    case Tm.Lam(x, a) => Hs.Lam(v => eval(env + (x -> v), a))
    case Tm.App(a,b) => Hs.App(eval(env,a),eval(env,b))
  }

def toHs(a:Tm):Hs = eval(Map(),a)
\end{lstlisting}

In order to convert from \id{Hs} to \id{Tm}, we have to extend the \id{Hs} data type with one additional constructor, that injects \id{Tm} terms into the \id{Hs} data type:

\begin{lstlisting}
case class ResTm(a:Tm) extends Hs
\end{lstlisting}

We're also going to need a fresh variable name generation facility, because \id{Hs} values have no variable names whereas \id{Tm} values do:

\begin{lstlisting}
var n = 0
def fresh() = { n += 1; s"x$n" }
\end{lstlisting}

We can now convert \id{Hs} values to \id{Tm} values:

\begin{lstlisting}
def freshLam(f:Tm => Tm):Tm = { val x = fresh(); Tm.Lam(x, f(Tm.Var(x))) }

def toTm(a:Hs):Tm =
  a match {
    case Hs.ResTm(a) => a
    case Hs.Lam(f) => freshLam(x => toTm(f(Hs.ResTm(x))))
    case Hs.App(a,b) => Tm.App(toTm(a),toTm(b))
  }
\end{lstlisting}

Here's an example:

\begin{lstlisting}
val zero = Hs.Lam(f => Hs.Lam(x => x))
val succ = Hs.Lam(n => Hs.Lam(f => Hs.Lam(z => Hs.App(Hs.App(n,f),Hs.App(f,z)))))

val one = Hs.App(succ,zero)
val two = Hs.App(succ,one)

toTm(two) /* App(Lam(x1,Lam(x2,Lam(x3,App(App(Var(x1),Var(x2)),App(Var(x2),Var(x3)))))),
                       App(Lam(x4,Lam(x5,Lam(x6,App(App(Var(x4),Var(x5)),
                                                         App(Var(x5),Var(x6)))))),
                             Lam(x7,Lam(x8,Var(x8))))) */

toTm(norm(two)) // Lam(x9,Lam(x10,App(Var(x9),App(Var(x9),Var(x10)))))
\end{lstlisting}

\subsection{Folding HOAS \& finally tagless}

The \id{toTm} : \id{Hs} $\to$ \id{Tm} and \id{norm} : \id{Hs} $\to$ \id{Hs} functions are somewhat similar.
We can factor out the pattern by defining a \id{fold} function on \id{Hs}, with which we can write functions \id{Hs} $\to$ \id{T} for any \id{T}.
The \id{fold} function takes smart constructors \id{app} : \id{T} $\times$ \id{T} $\to$ \id{T} and \id{lam} : (\id{T} $\to$ \id{T}) $\to$ \id{T} as arguments, and copies the \id{Hs} term with them to obtain a value of type \id{T}.
In order to write \id{fold}, we need to extend \id{Hs} with a new constructor, as we did before:

\begin{lstlisting}
case class Res(a:Object) extends Hs // hack for fold
\end{lstlisting}

We can then write \id{fold}:

\begin{lstlisting}
def fold[T](a:Hs, app : (T,T) => T, lam : (T => T) => T) : T =
  a match {
    case Hs.Res(x) => x.asInstanceOf[T]
    case Hs.Lam(f) => lam(t => fold(f(Hs.Res(t.asInstanceOf[Object])), app, lam))
    case Hs.App(a,b) => app(fold(a, app, lam), fold(b, app, lam))
  }
\end{lstlisting}

As you can see, this a bit of a hacky approach that requires unsafe casts.
It has the advantage of being fairly simple and require minimal changes to what we already have.
See \cite{BoxesGoBananas2003} for a non-hacky approach.

We can use \id{fold} to write \id{toTm} and \id{norm} as one-liners:

\begin{lstlisting}
def toTm(a:Hs):Tm = fold[Tm](a, Tm.App, freshLam)
def norm(a:Hs):Hs = fold[Hs](a, app, Hs.Lam)
\end{lstlisting}

An alternative is to represent \id{a:Hs} values \emph{as their folding function} \id{(app,lam) => fold(a, app, lam)}.
This approach is called \emph{finally tagless} \cite{FinallyTagless2007} and it works very nicely.
I would highly recommend checking out that paper.

\section{Typed normalization by evaluation}

Type directed normalization by evaluation can be used to put values in $\eta$ expanded form.
In $\eta$ expanded form we are only allowed to use variables $f : A \to B$ of function type as the first argument of $\ap$.
To use $f$ in any other place then we must instead write $f \equiv \lambda x. \ap(f,x)$.
We need type information because the types determine how much we $\eta$ expand:
\begin{itemize}
  \item Expanding $\lambda x. x$ at type $A \to A$ gives $\lambda x. x$
  \item Expanding $\lambda x. x$ at type $(A \to A) \to (A \to A)$ gives $\lambda f. \lambda x. \ap(f,x)$
\end{itemize}

We start by defining a data type for types:

\begin{lstlisting}
enum Ty:
  case Base
  case Arrow(a:Ty, b:Ty)
\end{lstlisting}

Instead of \id{norm} : \id{Hs} $\to$ \id{Hs}, we're going to use a tailored representation for normal forms, like we did for regular expressions.
We're going to have \id{norm} : \id{Hs} $\to$ \id{Sem} and \id{reify} : \id{Sem} $\to$ \id{Hs}, where \id{Sem} is the "semantic domain" tailored to representing normal forms.

In fact, the situation is a little bit more interesting.
The semantic domain is going to depend on the type of values we're representing: the domain $\mathsf{Sem}_A$ is going to be indexed by the type $A$ in the following way:
\begin{align*}
  \mathsf{Sem}_\mathsf{Base} &:= \mathsf{Hs} \\
  \mathsf{Sem}_{\mathsf{A} \to \mathsf{B}} &:= \mathsf{Sem}_\mathsf{A} \to \mathsf{Sem}_\mathsf{B}
\end{align*}
In other words, the semantic domain of base types is HOAS terms \id{Hs}, but the semantic domain for function types is going to be Scala functions between the respective semantic domains.
Unfortunately, we are not using Agda, and my Scala knowledge is insufficient to know if it is possible to do this in Scala.
In any case I'd like to keep the code here simple, and make it possible to translate into other languages without Agda's (or Scala's) fancy type system.
So we're going to smush the semantic domain together into a single type, and we're going to put the dependent types in comments:

\begin{lstlisting}
enum Sem:
  case Syn(a:Hs) // Sem_Base = syntactic terms Hs
  case Lam(f:Sem => Sem) // Sem_Arrow(A,B) = Sem_A -> Sem_B
\end{lstlisting}

Although the \id{Sem} domain doesn't have a case for \id{App}, we \emph{can} write a smart constructor for it:

\begin{lstlisting}
  // Smart constructor
  // appS : Sem_{A -> B} -> Sem_A -> Sem_B
  def appS(a:Sem, b:Sem):Sem =
    a match {
      case Sem.Lam(f) => f(b)
      // Types guarantee that we don't need any other case!
    }
\end{lstlisting}

Because we assume that \id{a} is of function type, we can ignore the \id{Syn} case.
We'll need to be careful to only pass \id{a}'s of function type into \id{appS}, of course.

We can write \id{norm} : \id{Hs} $\to$ \id{Sem} as a fold using this smart constructor:

\begin{lstlisting}
// norm : Hs_t -> Sem_t
def norm(x:Hs):Sem = fold[Sem](x, appS, Sem.Lam)
\end{lstlisting}

The more complicated direction turns out to be reifying \id{Sem} values back to syntactic \id{Hs} values:

\begin{lstlisting}
// reify : Sem_t -> Hs_t
def reify(t:Ty, x:Sem):Hs =
  (t,x) match {
    case (Ty.Arrow(a,b), Sem.Lam(f)) => Hs.Lam(y => reify(b, f(reflect(a, y))))
    case (Ty.Base, Sem.Syn(y)) => y
  }

// does eta expansion
// reflect : Hs_t -> Sem_t
def reflect(t:Ty, x:Hs):Sem =
  t match {
    case Ty.Arrow(a,b) => Sem.Lam(y => reflect(b, Hs.App(x, reify(a,y))))
    case Ty.Base => Sem.Syn(x)
  }
\end{lstlisting}

Because the \id{Sem} domain only contains function values for function types, we are \emph{forced} to do $\eta$-expansion:
there is simply no way to represent a plain variable $f$ in the semantic domain at function type, we must write $\lambda x. \ap(f,x)$.

By normalising and then reifying, we can do typed normalization by evaluation from HOAS terms to HOAS terms:

\begin{lstlisting}
// nbe : Hs_t -> Hs_t
def nbe(t:Ty, e:Hs) = reify(t, norm(e))
\end{lstlisting}

Using the conversion functions we can also get normalization by evaluation on ordinary terms:

\begin{lstlisting}
// nbeT : Tm_t -> Tm_t
def nbeT(t:Ty, e:Tm) = toTm(nbe(t,toHs(e)))
\end{lstlisting}

Here's an example that normalizes SK combinators \cite{NbEwiki2021}:

\begin{lstlisting}
val k = Hs.Lam(x => Hs.Lam(y => x))
val s = Hs.Lam(x => Hs.Lam(y => Hs.Lam(z => Hs.App(Hs.App(x,z), Hs.App(y,z)))))
val skk = Hs.App(Hs.App(s,k),k)

toTm(skk) /* App(App(Lam(x11,Lam(x12,Lam(x13,
                  App(App(Var(x11),Var(x13)),App(Var(x12),Var(x13)))))),
                     Lam(x14,Lam(x15,Var(x14)))), Lam(x16,Lam(x17,Var(x16)))) */

val tb = Ty.Arrow(Ty.Base,Ty.Base)

// normalizes to the identify function
toTm(nbe(tb, skk)) // Lam(x18,Var(x18))

val tbb = Ty.Arrow(tb, tb)

// at higher type, it eta expands the identity function
toTm(nbe(tbb, skk)) // Lam(x19,Lam(x20,App(Var(x19),Var(x20))))
\end{lstlisting}

I would highly recommend looking at Sam Lindley's slide deck \cite{NbELindley2016slides} if you want to learn more about typed normalization by evaluation.
It is excellent and explains simple normalization by evaluation very clearly, but also goes much beyond this.

\section{Summary}

We saw that the essence of these techniques is the \emph{smart constructor} that ensures that its return value is in normal form.
On top of those, we can build a \emph{smart copy function} \id{norm} that copies a value but constructs the copy using smart constructors, in order to rewrite it to normal form.
The smart copy function is the same as \id{fold}\emph{ing} the data type with the smart constructors.
The smart constructors do not have to use the original syntactic representation: we can use a \emph{tailored normal form representation} as we did with regular expressions with \id{Seq} represented as a list and \id{Alt} as as set.
In this case, the smart copy function has the syntactic representation type as input and the normal form representation type as output.
We can \id{reify} the normal form representation back into the syntactic representation.

Hereditary substitution and untyped normalization by evaluation are both based on smart constructors for $\ap$,
but use a different representation and mechanism to compute the substitution.
Typed normalization by evaluation uses a separate semantic domain to tailored to representing normal forms.
This semantic domain is indexed by the type of the expressions.
We can still separate the AST $\leftrightarrow$ HOAS conversion and HOAS $\leftrightarrow$ Normal Form transformation, which makes each individual piece a bit simpler.

\paragraph{Acknowledgements.} I thank Arjen Rouvoet for his suggestions on style and typography,
and Molossus Spookee, Paolo Giarrusso, and Edwin Brady for their suggestions.

\bibliographystyle{alphaurl}
\bibliography{references}


\end{document}